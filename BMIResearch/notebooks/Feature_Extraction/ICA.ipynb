{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R8OXLLFoC20",
        "outputId": "ed1b7b98-047e-407a-bc1a-13a4cc9001dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9_LYs5yoKRV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import codecs, json\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import time\n",
        "import math\n",
        "from sklearn.decomposition import FastICA\n",
        "\n",
        "import sys\n",
        "sys.path.append('drive/MyDrive/BmiResearch')\n",
        "from constants import constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeGWz89RoKUA",
        "outputId": "93bc717b-26a3-4ace-d53b-271097130fef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SLF', 'ASR', 'NOSP']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "constants.SIGNAL_PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13oWwtW_oKWq"
      },
      "outputs": [],
      "source": [
        "for sp in constants.SIGNAL_PROCESSING:\n",
        "  output_path = f'{constants.PREPROCESSED_DATASET_PATH}/{sp}_ICA'\n",
        "  print('output_path: ', output_path)\n",
        "\n",
        "  if sp == 'NOSP':\n",
        "    actual_base_dataset_path = constants.BASE_DATASET_PATH\n",
        "  else:\n",
        "    actual_base_dataset_path = f'{constants.PREPROCESSED_DATASET_PATH}/{sp}'\n",
        "  print(\"actual_base_dataset_path = \", actual_base_dataset_path)\n",
        "\n",
        "  for subject in sorted(os.listdir(actual_base_dataset_path)):\n",
        "    print(subject)\n",
        "    experiment_settings = dict()\n",
        "    experiment_settings['general_params'] = {'low_filter':constants.low_filter,\n",
        "                                            'high_filter':constants.high_filter,\n",
        "                                            'frequency':constants.freq,\n",
        "                                            'minutes_for_test':constants.minutes_for_test,\n",
        "                                            'window_size':constants.window_size,\n",
        "                                            'overlap':constants.overlap,\n",
        "                                            'EEG_CHANNELS':constants.EEG_CHANNELS}\n",
        "    experiment_settings['feature_extraction'] = 'ICA'\n",
        "    experiment_settings['DateTime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    experiment_settings['BASE_DATASET_PATH'] = constants.BASE_DATASET_PATH\n",
        "    experiment_settings['OUTPUT_PATH'] = output_path\n",
        "\n",
        "    output_path_subject = (f'{output_path}/{subject}')\n",
        "    os.makedirs(output_path_subject)\n",
        "\n",
        "    experiment_settings[subject] = dict()\n",
        "\n",
        "    # Fit ICA\n",
        "    fit_df = codecs.open(f'{actual_base_dataset_path}/{subject}/X_fit.json', 'r', encoding='utf-8').read()\n",
        "    fit_df = json.loads(fit_df)\n",
        "    fit_df = np.array(fit_df)\n",
        "\n",
        "    # !!!!! ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
        "    one_ica = FastICA(random_state=11, max_iter=2000, tol=0.0001)\n",
        "    print(\"fit_df.shape\", fit_df.shape)\n",
        "    one_ica.fit(fit_df)\n",
        "\n",
        "    ica_fit = one_ica.transform(fit_df)\n",
        "\n",
        "    ica_fit = ica_fit.tolist()\n",
        "    json.dump(ica_fit, codecs.open(f'{output_path_subject}/X_fit.json', 'w', encoding='utf-8'),\n",
        "      separators=(',', ':'),\n",
        "      sort_keys=True,\n",
        "      indent=4)\n",
        "\n",
        "    # process train\n",
        "    chanks_train = codecs.open(f'{actual_base_dataset_path}/{subject}/X_train_chunks.json', 'r', encoding='utf-8').read()\n",
        "    chanks_train = json.loads(chanks_train)\n",
        "    chanks_train = np.array(chanks_train)\n",
        "\n",
        "    ica_train = []\n",
        "    for i in range(chanks_train.shape[0]):\n",
        "        ica_train.append(one_ica.transform(chanks_train[i].T).T)\n",
        "    ica_train = np.array(ica_train)\n",
        "\n",
        "    ica_train = ica_train.tolist()\n",
        "    json.dump(ica_train, codecs.open(f'{output_path_subject}/X_train_chunks.json', 'w', encoding='utf-8'),\n",
        "      separators=(',', ':'),\n",
        "      sort_keys=True,\n",
        "      indent=4)\n",
        "\n",
        "    # process test\n",
        "    chanks_test = codecs.open(f'{actual_base_dataset_path}/{subject}/X_test_chunks.json', 'r', encoding='utf-8').read()\n",
        "    chanks_test = json.loads(chanks_test)\n",
        "    chanks_test = np.array(chanks_test)\n",
        "\n",
        "    starttime = time.perf_counter()\n",
        "    ica_test = []\n",
        "    for i in range(chanks_test.shape[0]):\n",
        "        ica_test.append(one_ica.transform(chanks_test[i].T).T)\n",
        "\n",
        "    proc_end = time.perf_counter() - starttime\n",
        "    ica_test = np.array(ica_test)\n",
        "\n",
        "    proc_1ch_s = round(proc_end / chanks_test.shape[0], 5)\n",
        "    experiment_settings[subject]['proc_1_test_ch_s'] = proc_1ch_s\n",
        "    experiment_settings[subject]['proc_test_s'] = round(proc_end, 5)\n",
        "    experiment_settings[subject]['len_test'] = chanks_test.shape[0]\n",
        "    experiment_settings[subject]['output_path_subject'] = output_path_subject\n",
        "\n",
        "    ica_test = ica_test.tolist()\n",
        "    json.dump(ica_test, codecs.open(f'{output_path_subject}/X_test_chunks.json', 'w', encoding='utf-8'),\n",
        "      separators=(',', ':'),\n",
        "      sort_keys=True,\n",
        "      indent=4)\n",
        "\n",
        "    json.dump(experiment_settings, codecs.open(f'{output_path_subject}/experiment_settings.json', 'w', encoding='utf-8'),\n",
        "      separators=(',', ':'),\n",
        "      sort_keys=True,\n",
        "      indent=4)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}