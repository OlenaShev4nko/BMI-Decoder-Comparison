{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9MmEXk-n6tHZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MmEXk-n6tHZ",
        "outputId": "ebf15ec6-f6cf-40b2-96df-9d3e52a5fdb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "initial_id",
        "outputId": "c09d6cab-801c-4e1c-e852-3c9ae9d90a05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from mne) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from mne) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (3.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import codecs, json\n",
        "from tqdm import tqdm\n",
        "import typing as t\n",
        "import numpy as np\n",
        "!pip install mne\n",
        "import mne\n",
        "import pandas as pd\n",
        "import scipy.signal as sps\n",
        "from scipy import stats\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/BmiResearch')\n",
        "\n",
        "from constants.constants import ORIGINAL_DATASET_PATH, PREPROCESSED_DATASET_PATH\n",
        "from constants.constants import EEG_CHANNELS\n",
        "from utils.debugger import logger\n",
        "# from pipeline_structure.preprocessing.preprocessed_dataset import to_preprocessed_dataset\n",
        "from utils.processer import train_test_split_time_eeg, sliding_window_iter, create_output_for_chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z5YZdppKUHAp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5YZdppKUHAp",
        "outputId": "e1d91e5a-8998-49e6-d7f1-dbec1c794040"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(EEG_CHANNELS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a1eab15f1052b14",
      "metadata": {
        "id": "8a1eab15f1052b14"
      },
      "outputs": [],
      "source": [
        "low_filter = 1\n",
        "high_filter = 20\n",
        "frequency = 500\n",
        "minutes_for_test = 2\n",
        "size = 100\n",
        "overlap = 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CY5fniCfj4SW",
      "metadata": {
        "id": "CY5fniCfj4SW"
      },
      "outputs": [],
      "source": [
        "def preprocess_eeg_data(low_filter: float, high_filter: float, frequency: float, subject_eeg_folder: str,\n",
        "                        subject: str, eeg_file: str, events_file: str, preprocessed_path: str):\n",
        "    try:\n",
        "\n",
        "        logger.info(f\"Reading EEG data from {subject}\")\n",
        "        raw = mne.io.read_raw_eeglab(f'{subject_eeg_folder}{eeg_file}', preload=True)\n",
        "\n",
        "        raw.filter(low_filter, high_filter)\n",
        "\n",
        "        eeg_data = raw.get_data()\n",
        "        eeg_channels = [element for element in raw.ch_names if element in EEG_CHANNELS]\n",
        "\n",
        "        events_dataframe = pd.read_csv(f'{subject_eeg_folder}{events_file}', sep='\\t')\n",
        "\n",
        "        events_dataframe['time'] = (events_dataframe['sample'].astype(int)) / frequency\n",
        "        events_dataframe['onset_sample'] = (events_dataframe['onset'] * frequency).astype(int)\n",
        "\n",
        "        task_dict = events_dataframe.set_index('onset_sample')['value'].to_dict()\n",
        "        eeg_events_dataframe = pd.DataFrame(eeg_data.T, columns=raw.ch_names)\n",
        "\n",
        "        tasks_list = []\n",
        "        task = ''\n",
        "\n",
        "        for k in list(eeg_events_dataframe.index):\n",
        "            if k in task_dict.keys():\n",
        "                task = task_dict[k]\n",
        "            tasks_list.append(task)\n",
        "\n",
        "        eeg_dataframe = eeg_events_dataframe[eeg_channels].copy()\n",
        "        eeg_dataframe['task'] = tasks_list\n",
        "\n",
        "        filtered_eeg_dataframe = eeg_dataframe[eeg_dataframe['task'].isin(['RightTO', 'RightHS', 'LeftTO', 'LeftHS'])]\n",
        "        print(filtered_eeg_dataframe.columns)\n",
        "\n",
        "        filtered_eeg_dataframe.to_csv(f'{preprocessed_path}/eeg_data.csv', index=False)\n",
        "        logger.info(f'Saved to {preprocessed_path}')\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f'Unexpected error: {e}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BpBWy-aNi0cG",
      "metadata": {
        "id": "BpBWy-aNi0cG"
      },
      "outputs": [],
      "source": [
        "def to_preprocessed_dataset(low_filter, high_filter, frequency):\n",
        "    try:\n",
        "        logger.info(f\"Reading BIDS dataset from {ORIGINAL_DATASET_PATH}\")\n",
        "        subjects_list = sorted(os.listdir(ORIGINAL_DATASET_PATH))\n",
        "        print(subjects_list)\n",
        "\n",
        "        for i, subject in tqdm(enumerate(subjects_list[6:]), total=len(subjects_list[6:])):\n",
        "            preprocessed_path = (f'{PREPROCESSED_DATASET_PATH}/low-{low_filter}-high-{high_filter}-frequency'\n",
        "                                 f'-{frequency}/{subject}')\n",
        "\n",
        "            os.makedirs(preprocessed_path)\n",
        "\n",
        "            subject_eeg_folder = f\"{ORIGINAL_DATASET_PATH}/{subject}/eeg/\"\n",
        "            subject_eeg_files = os.listdir(subject_eeg_folder)\n",
        "\n",
        "            file_types = ['channels.tsv', 'eeg.set', 'events.tsv']\n",
        "            selected_files = {ftype: next(file_name for file_name in subject_eeg_files if ftype in file_name)\n",
        "                              for ftype in file_types}\n",
        "\n",
        "            preprocess_eeg_data(low_filter, high_filter, frequency, subject_eeg_folder, subject,\n",
        "                                selected_files['eeg.set'], selected_files['events.tsv'],\n",
        "                                preprocessed_path)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        logger.error(f'Dataset path {ORIGINAL_DATASET_PATH} not found.')\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f'Unexpected error: {e}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kfdVU7EYmsjm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfdVU7EYmsjm",
        "outputId": "7649005a-e371-4c97-da3e-4b365b582b95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['low-1-high-20-frequency-500', 'baseline_chunked_data', 'SLF', 'ASR', 'ASR_ICA', 'NOSP_ICA', 'SLF_ICA', 'SLF_CSP', 'ASR_CSP', 'NOSP_CSP', 'SLF_STFT', 'ASR_STFT', 'NOSP_STFT']\n"
          ]
        }
      ],
      "source": [
        "print(os.listdir(PREPROCESSED_DATASET_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-13NwvZTkLde",
      "metadata": {
        "id": "-13NwvZTkLde"
      },
      "outputs": [],
      "source": [
        "to_preprocessed_dataset(low_filter, high_filter, frequency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QcvGNIXx6bGc",
      "metadata": {
        "id": "QcvGNIXx6bGc"
      },
      "outputs": [],
      "source": [
        "def prep_chanks(data_chanks_list_train):\n",
        "    print('[prep_chanks]')\n",
        "    final_train_set = []\n",
        "    for chank_df in tqdm(data_chanks_list_train):\n",
        "        final_train_set.append(chank_df[EEG_CHANNELS].copy().T)\n",
        "    return np.array(final_train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7fb8bc5d5016a3b",
      "metadata": {
        "id": "c7fb8bc5d5016a3b"
      },
      "outputs": [],
      "source": [
        "preprocessed_path = (f'{PREPROCESSED_DATASET_PATH}/low-{low_filter}-high-{high_filter}-frequency'\n",
        "                         f'-{frequency}')\n",
        "\n",
        "if not os.path.exists(preprocessed_path):\n",
        "    to_preprocessed_dataset(low_filter, high_filter, frequency)\n",
        "\n",
        "for subject in sorted(os.listdir(preprocessed_path)):\n",
        "  try:\n",
        "    print(subject)\n",
        "    subject_path = f'{preprocessed_path}/{subject}/eeg_data.csv'\n",
        "    preprocessed_eeg_train, preprocessed_eeg_test = train_test_split_time_eeg(subject_path, minutes_for_test, frequency)\n",
        "    output_path = (f'{PREPROCESSED_DATASET_PATH}/baseline_chunked_data_2/{subject}')\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "    print('chunks_test')\n",
        "    chunks_test = list(sliding_window_iter(preprocessed_eeg_test, size, overlap))\n",
        "    # logger.info(f'Length of chunks for test = {len(chunks_test)} data windows')\n",
        "    print(f'Length of chunks for test = {len(chunks_test)} data windows')\n",
        "    print('y_test')\n",
        "    y_test = create_output_for_chunks(chunks_test)\n",
        "    chunks_test = prep_chanks(chunks_test)\n",
        "\n",
        "\n",
        "    chunks_test = chunks_test.tolist()\n",
        "    json.dump(chunks_test, codecs.open(f'{output_path}/X_test_chunks.json', 'w', encoding='utf-8'),\n",
        "      separators=(',', ':'),\n",
        "      sort_keys=True,\n",
        "      indent=4) ### this saves the array in .json format\n",
        "\n",
        "    print('y_test write')\n",
        "    y_test = y_test.tolist()\n",
        "    json.dump(y_test, codecs.open(f'{output_path}/y_test_chunks.json', 'w', encoding='utf-8'),\n",
        "      separators=(',', ':'),\n",
        "      sort_keys=True,\n",
        "      indent=4) ### this saves the array in .json format\n",
        "\n",
        "    print('fit_X')\n",
        "    fit_X = preprocessed_eeg_train[EEG_CHANNELS].to_numpy()\n",
        "    fit_X = fit_X.tolist()\n",
        "    json.dump(fit_X, codecs.open(f'{output_path}/X_fit.json', 'w', encoding='utf-8'),\n",
        "      separators=(',', ':'),\n",
        "      sort_keys=True,\n",
        "      indent=4)\n",
        "    class_names_dict = {'RightTO': 0, 'RightHS': 1, 'LeftTO': 2, 'LeftHS': 3}\n",
        "    print('fit_y')\n",
        "    fit_y = np.array([class_names_dict[el] for el in preprocessed_eeg_train['task'].tolist()])\n",
        "    fit_y = fit_y.tolist()\n",
        "    json.dump(fit_y, codecs.open(f'{output_path}/y_fit.json', 'w', encoding='utf-8'),\n",
        "      separators=(',', ':'),\n",
        "      sort_keys=True,\n",
        "      indent=4) ### this saves the array in .json format\n",
        "\n",
        "    print('chunks_train')\n",
        "    chunks_train = list(sliding_window_iter(preprocessed_eeg_train, size, overlap))\n",
        "    # logger.info(f'Length of chunks for train = {len(chunks_train)} data windows')\n",
        "    print(f'Length of chunks for train = {len(chunks_train)} data windows')\n",
        "    print('y_train')\n",
        "    y_train = create_output_for_chunks(chunks_train)\n",
        "    chunks_train = prep_chanks(chunks_train)\n",
        "    chunks_train = chunks_train.tolist()\n",
        "    json.dump(chunks_train, codecs.open(f'{output_path}/X_train_chunks.json', 'w', encoding='utf-8'),\n",
        "      separators=(',', ':'),\n",
        "      sort_keys=True,\n",
        "      indent=4)\n",
        "    print('y_train write')\n",
        "    y_train = y_train.tolist()\n",
        "    json.dump(y_train, codecs.open(f'{output_path}/y_train_chunks.json', 'w', encoding='utf-8'),\n",
        "      separators=(',', ':'),\n",
        "      sort_keys=True,\n",
        "      indent=4)\n",
        "\n",
        "#   filtered_eeg.to_csv(f'{result_path}/eeg_data.csv', index=False)\n",
        "\n",
        "  except Exception as e:\n",
        "      print(f'Unexpected error: {e}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}