{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOSHCXE3m9F1",
        "outputId": "a9bc2dfe-c210-4cd7-e13c-1ab765a5feb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmLzZfLJm6uA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import codecs, json\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import time\n",
        "import math\n",
        "import joblib\n",
        "\n",
        "import sys\n",
        "sys.path.append('drive/MyDrive/BmiResearch')\n",
        "from constants import constants\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "import tracemalloc\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7jFl23dm9Dm"
      },
      "outputs": [],
      "source": [
        "class_names_dict = {'RightTO': 0, 'RightHS': 1, 'LeftTO': 2, 'LeftHS': 3}\n",
        "class_names_dict_1 = {0: 'RightTO',  1: 'RightHS',  2: 'LeftTO',  3: 'LeftHS'}\n",
        "\n",
        "def calculate_weighted_metrics(y_test, y_pred):\n",
        "    \"\"\"'weighted':\n",
        "    Calculate metrics for each label, and find their average weighted by support\n",
        "    (the number of true instances for each label). This alters ‘macro’ to account for\n",
        "    label imbalance; it can result in an F-score that is not between\n",
        "    precision and recall.\"\"\"\n",
        "    ACC = accuracy_score(y_test, y_pred)\n",
        "    PPV = precision_score(y_test, y_pred, average='weighted')\n",
        "    TPR = recall_score(y_test, y_pred, average='weighted')\n",
        "    F1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    return ACC, PPV, TPR, F1\n",
        "\n",
        "\n",
        "def calculate_weighted_metrics_per_class(y_test, y_pred):\n",
        "    ACC = accuracy_score(y_test, y_pred)\n",
        "    PPV = precision_score(y_test, y_pred, average=None)\n",
        "    TPR = recall_score(y_test, y_pred, average=None)\n",
        "    F1 = f1_score(y_test, y_pred, average=None)\n",
        "    PPV = [round(el, 3) for el in PPV]\n",
        "    TPR = [round(el, 3) for el in TPR]\n",
        "    F1 = [round(el, 3) for el in F1]\n",
        "    return ACC, PPV, TPR, F1\n",
        "\n",
        "def apply_standard_scaling(data_chanks_list_train, one_scaler):\n",
        "    print('[apply_standard_scaling]')\n",
        "    print(\"data_chanks_list_train shape = \", data_chanks_list_train[0].shape)\n",
        "    final_train_set = []\n",
        "    for chank_df in tqdm(data_chanks_list_train):\n",
        "        final_train_set.append(one_scaler.transform(chank_df.T).T)\n",
        "    return np.array(final_train_set)\n",
        "\n",
        "def flat_aray(chanks):\n",
        "    new_chanks = [el.flatten().copy() for el in chanks]\n",
        "    return np.array(new_chanks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Lnj-WDfWT2s",
        "outputId": "15111669-8157-4e85-fead-d8b460283d82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SLF', 'ASR', 'NOSP']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "constants.SIGNAL_PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMfGfKueWXQN",
        "outputId": "49cefe7b-76f9-4736-ef54-de6f5740713a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ICA', 'CSP', 'NOFE']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "constants.FEATURE_EXTRACTION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "constants.BASE_DATASET_PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ul-VBabisycu",
        "outputId": "1ef88795-138e-4f8c-aad1-26792323a424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drive/MyDrive/BmiResearch/data/datasets/preprocessed/a_walk_in_the_park/baseline_chunked_data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDa4IwbNvoax"
      },
      "outputs": [],
      "source": [
        "for sp in constants.SIGNAL_PROCESSING: # ['SLF', 'ASR', 'NOSP']\n",
        "  for fe in constants.FEATURE_EXTRACTION: # ['ICA', 'CSP', 'NOFE']\n",
        "    output_path = f'{constants.MODELS}/svm_new_chanks/{sp}_{fe}'\n",
        "    print('output_path: ', output_path)\n",
        "\n",
        "    if (sp == 'NOSP') & (fe == 'NOFE'):\n",
        "      dataset_path = constants.BASE_DATASET_PATH\n",
        "    elif (sp != 'NOSP') & (fe == 'NOFE'):\n",
        "      dataset_path = f'{constants.PREPROCESSED_DATASET_PATH}/{sp}'\n",
        "    else:\n",
        "      dataset_path = f'{constants.PREPROCESSED_DATASET_PATH}/{sp}_{fe}'\n",
        "    print('dataset_path: ', dataset_path)\n",
        "\n",
        "    for subject in sorted(os.listdir(dataset_path)):\n",
        "      print(subject)\n",
        "      experiment_settings = dict()\n",
        "      experiment_settings['general_params'] = {'low_filter':constants.low_filter,\n",
        "                                              'high_filter':constants.high_filter,\n",
        "                                              'frequency':constants.freq,\n",
        "                                              'minutes_for_test':constants.minutes_for_test,\n",
        "                                              'window_size':constants.window_size,\n",
        "                                              'overlap':constants.overlap,\n",
        "                                              'EEG_CHANNELS':constants.EEG_CHANNELS}\n",
        "      experiment_settings['subject'] = subject\n",
        "      experiment_settings['signal_processing'] = sp\n",
        "      experiment_settings['feature_extraction'] = fe\n",
        "      experiment_settings['classification'] = 'SVM'\n",
        "      experiment_settings['DateTime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "      experiment_settings['dataset_path'] = dataset_path\n",
        "      output_path_subject = (f'{output_path}/{subject}')\n",
        "      experiment_settings['OUTPUT_PATH'] = output_path_subject\n",
        "      os.makedirs(output_path_subject)\n",
        "\n",
        "      # fit\n",
        "      fit_df = codecs.open(f'{dataset_path}/{subject}/X_fit.json', 'r', encoding='utf-8').read()\n",
        "      fit_df = json.loads(fit_df)\n",
        "      fit_df = np.array(fit_df)\n",
        "\n",
        "      one_scaler = StandardScaler()\n",
        "      one_scaler.fit(fit_df)\n",
        "\n",
        "      # train\n",
        "      chanks_train = codecs.open(f'{dataset_path}/{subject}/X_train_chunks.json', 'r', encoding='utf-8').read()\n",
        "      chanks_train = json.loads(chanks_train)\n",
        "      chanks_train = np.array(chanks_train)\n",
        "\n",
        "      # test\n",
        "      chanks_test = codecs.open(f'{dataset_path}/{subject}/X_test_chunks.json', 'r', encoding='utf-8').read()\n",
        "      chanks_test = json.loads(chanks_test)\n",
        "      chanks_test = np.array(chanks_test)\n",
        "\n",
        "      # y train\n",
        "      final_y_train_list = codecs.open(f'{constants.BASE_DATASET_PATH}/{subject}/y_train_chunks.json', 'r', encoding='utf-8').read()\n",
        "      final_y_train_list = json.loads(final_y_train_list)\n",
        "      final_y_train_list = np.array(final_y_train_list)\n",
        "\n",
        "      # y test\n",
        "      final_y_test_list = codecs.open(f'{constants.BASE_DATASET_PATH}/{subject}/y_test_chunks.json', 'r', encoding='utf-8').read()\n",
        "      final_y_test_list = json.loads(final_y_test_list)\n",
        "      final_y_test_list = np.array(final_y_test_list)\n",
        "\n",
        "      svc_train_set = apply_standard_scaling(chanks_train, one_scaler)\n",
        "\n",
        "      starttime = time.perf_counter()\n",
        "      svc_test_set = apply_standard_scaling(chanks_test, one_scaler)\n",
        "      duration_standard_scaling_s = (time.perf_counter() - starttime)\n",
        "      scale_1ch_s = round(duration_standard_scaling_s / chanks_test.shape[0], 10)\n",
        "      experiment_settings['scale_1ch_s'] = scale_1ch_s\n",
        "\n",
        "\n",
        "      svc_train_set = flat_aray(svc_train_set)\n",
        "      svc_test_set = flat_aray(svc_test_set)\n",
        "      X_train1, X_val, y_train1, y_val = train_test_split(svc_train_set, final_y_train_list,\n",
        "                                                                                  test_size=0.2,\n",
        "                                                                                  random_state=42)\n",
        "\n",
        "      param_grid = {'C': [1, 5, 10, 20, 40, 50, 80, 90, 100, 110, 250, 500, 750, 1000],\n",
        "                                            'gamma': ['scale'],\n",
        "                                            'kernel': ['rbf'],\n",
        "                                            'decision_function_shape': ['ovr']}\n",
        "      starttime = time.perf_counter()\n",
        "      tracemalloc.start()\n",
        "      grid = GridSearchCV(SVC(class_weight='balanced', break_ties=True, cache_size=2048), param_grid,\n",
        "                          refit=True, cv=5, verbose=3)\n",
        "      grid.fit(X_val, y_val)\n",
        "      bp = grid.best_params_\n",
        "      # print best parameter after tuning\n",
        "      print(bp)\n",
        "      experiment_settings['best_params'] = bp\n",
        "      # Specifies the kernel type to be used in the algorithm. If none is given, ‘rbf’ will be used.\n",
        "      model = SVC(C=bp['C'], cache_size=2048, gamma=bp['gamma'], kernel='rbf',\n",
        "            class_weight='balanced',\n",
        "            break_ties=True, decision_function_shape='ovr')\n",
        "      model.fit(svc_train_set, final_y_train_list)\n",
        "      duration_train_min = round((time.perf_counter() - starttime) / 60, 3)\n",
        "      current, peak_train_MB = tracemalloc.get_traced_memory()\n",
        "      print(\n",
        "          f\"Final current memory usage, MB [{current / (1024 * 1024):0.2f}]~peak memory usage, MB [{peak_train_MB / (1024 * 1024):0.2f}]~time [{duration_train_min}] minutes, \")\n",
        "\n",
        "      tracemalloc.reset_peak()\n",
        "      tracemalloc.clear_traces()\n",
        "      tracemalloc.stop()\n",
        "\n",
        "      starttime = time.perf_counter()\n",
        "      tracemalloc.start()\n",
        "\n",
        "      predictions = model.predict(svc_test_set)\n",
        "      joblib.dump(model, f'{output_path_subject}/model_svc_{sp}_{fe}.pkl')\n",
        "      labels = unique_labels(final_y_test_list, predictions)\n",
        "      labels = [class_names_dict_1[el] for el in labels]\n",
        "      ACC_w, PPV_w, TPR_w, F1_w = calculate_weighted_metrics(final_y_test_list, predictions)\n",
        "      ACC, PPV, TPR, F1 = calculate_weighted_metrics_per_class(final_y_test_list, predictions)\n",
        "      current, peak_predict = tracemalloc.get_traced_memory()\n",
        "      sec_predict = round((time.perf_counter() - starttime), 3)\n",
        "      tracemalloc.reset_peak()\n",
        "      tracemalloc.clear_traces()\n",
        "      tracemalloc.stop()\n",
        "\n",
        "      proc_1ch_s = round(sec_predict / chanks_test.shape[0], 5)\n",
        "      experiment_settings['pred_1_ch_s'] = proc_1ch_s\n",
        "      experiment_settings['len_test'] = chanks_test.shape[0]\n",
        "\n",
        "      experiment_settings['y_test'] = list(final_y_test_list[:])\n",
        "      experiment_settings['prediction'] = list(predictions[:])\n",
        "      # print('Y test:', list(final_y_test_list[:]))\n",
        "      # print('Prediction:', list(predictions[:]))\n",
        "      experiment_settings['labels'] = labels\n",
        "      cm = confusion_matrix(final_y_test_list, predictions, normalize='true')\n",
        "      experiment_settings['confusion_matrix'] = experiment_settings['confusion_matrix'] = cm.tolist()\n",
        "      print(cm)\n",
        "      print(\"ACC_w, PPV_w, TPR_w, F1_w = \", ACC_w, PPV_w, TPR_w, F1_w)\n",
        "      print(\"ACC, PPV, TPR, F1 = \", ACC, PPV, TPR, F1)\n",
        "\n",
        "      experiment_settings['peak_predict_MB'] = round(peak_predict / (1024 * 1024), 2)\n",
        "      experiment_settings['sec_predict'] = sec_predict\n",
        "      experiment_settings['accuracy_score'] = round(ACC_w, 3)\n",
        "      experiment_settings['precision_score'] = round(PPV_w, 3)\n",
        "      experiment_settings['recall_score'] = round(TPR_w, 3)\n",
        "      experiment_settings['f1_score'] = round(F1_w, 3)\n",
        "      print(\"round(F1_w, 3) = \", round(F1_w, 3))\n",
        "\n",
        "      for i, val in enumerate(labels):\n",
        "          experiment_settings[f'{val}_precision_score'] = f'{round(PPV[i], 3)}'\n",
        "          experiment_settings[f'{val}_recall_score'] = f'{round(TPR[i], 3)}'\n",
        "          experiment_settings[f'{val}_f1_score'] = f'{round(F1[i], 3)}'\n",
        "\n",
        "      json.dump(experiment_settings, codecs.open(f'{output_path_subject}/experiment_results.json', 'w', encoding='utf-8'),\n",
        "      separators=(',', ':'),\n",
        "      sort_keys=True,\n",
        "      indent=4, default=str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFS6Hbvzm9MJ"
      },
      "outputs": [],
      "source": [
        "experiment_settings['confusion_matrix'] = cm.tolist()\n",
        "\n",
        "json.dump(experiment_settings, codecs.open(f'{output_path_subject}/experiment_results.json', 'w', encoding='utf-8'),\n",
        "      separators=(',', ':'),\n",
        "      sort_keys=True,\n",
        "      indent=4, default=str)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}