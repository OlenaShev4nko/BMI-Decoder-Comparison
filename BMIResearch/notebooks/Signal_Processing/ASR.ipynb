{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvPvfvdRcar6",
        "outputId": "2351dec0-a211-4523-f525-18b576ea65ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import codecs, json\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import time\n",
        "import math\n",
        "\n",
        "import sys\n",
        "sys.path.append('drive/MyDrive/BmiResearch')\n",
        "from pipeline_structure.signal_processing.asr_utils import clean_windows, asr_calibrate, asr_process, apply_asr\n",
        "\n",
        "from constants import constants"
      ],
      "metadata": {
        "id": "HhGtkRBwd7NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = f'{constants.PREPROCESSED_DATASET_PATH}/ASR'\n",
        "output_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zOLS6Twud7UG",
        "outputId": "0b608318-33f5-4787-fadb-2e157ec8ae15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drive/MyDrive/BmiResearch/data/datasets/preprocessed/a_walk_in_the_park/ASR'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for subject in sorted(os.listdir(constants.BASE_DATASET_PATH)):\n",
        "  print(subject)\n",
        "\n",
        "  experiment_settings = dict()\n",
        "\n",
        "  experiment_settings['general_params'] = {'low_filter':constants.low_filter,\n",
        "                                          'high_filter':constants.high_filter,\n",
        "                                          'frequency':constants.freq,\n",
        "                                          'minutes_for_test':constants.minutes_for_test,\n",
        "                                          'window_size':constants.window_size,\n",
        "                                          'overlap':constants.overlap,\n",
        "                                          'EEG_CHANNELS':constants.EEG_CHANNELS}\n",
        "  experiment_settings['signal_processing'] = 'ASR'\n",
        "  experiment_settings['DateTime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "  experiment_settings['BASE_DATASET_PATH'] = constants.BASE_DATASET_PATH\n",
        "  experiment_settings['OUTPUT_PATH'] = output_path\n",
        "\n",
        "  output_path_subject = (f'{output_path}/{subject}')\n",
        "  os.makedirs(output_path_subject)\n",
        "\n",
        "  experiment_settings[subject] = dict()\n",
        "\n",
        "  # Fit ASR\n",
        "  fit_df = codecs.open(f'{constants.BASE_DATASET_PATH}/{subject}/X_fit.json', 'r', encoding='utf-8').read()\n",
        "  fit_df = json.loads(fit_df)\n",
        "  fit_df = np.array(fit_df)\n",
        "  pre_cleaned, _ = clean_windows(fit_df.T, constants.freq, max_bad_chans=0.1)\n",
        "  M, T = asr_calibrate(pre_cleaned, constants.freq, cutoff=20)\n",
        "  fit_df_s_asr = asr_process(fit_df.T, constants.freq, M, T)\n",
        "  fit_df_s_asr = fit_df_s_asr.T\n",
        "  fit_df_s_asr = fit_df_s_asr.tolist()\n",
        "  json.dump(fit_df_s_asr, codecs.open(f'{output_path_subject}/X_fit.json', 'w', encoding='utf-8'),\n",
        "    separators=(',', ':'),\n",
        "    sort_keys=True,\n",
        "    indent=4)\n",
        "\n",
        "  # process test\n",
        "  chanks_test = codecs.open(f'{constants.BASE_DATASET_PATH}/{subject}/X_test_chunks.json', 'r', encoding='utf-8').read()\n",
        "  chanks_test = json.loads(chanks_test)\n",
        "  chanks_test = np.array(chanks_test)\n",
        "\n",
        "  starttime = time.perf_counter()\n",
        "  chanks_test_asr = apply_asr(chanks_test, constants.freq, M, T)\n",
        "  proc_end = time.perf_counter() - starttime\n",
        "  proc_1ch_s = round(proc_end / chanks_test_asr.shape[0], 5)\n",
        "  experiment_settings[subject]['proc_1_test_ch_s'] = proc_1ch_s\n",
        "  experiment_settings[subject]['proc_test_s'] = round(proc_end, 5)\n",
        "  experiment_settings[subject]['len_test'] = chanks_test.shape[0]\n",
        "  experiment_settings[subject]['output_path_subject'] = output_path_subject\n",
        "\n",
        "  chanks_test_asr = chanks_test_asr.tolist()\n",
        "  json.dump(chanks_test_asr, codecs.open(f'{output_path_subject}/X_test_chunks.json', 'w', encoding='utf-8'),\n",
        "    separators=(',', ':'),\n",
        "    sort_keys=True,\n",
        "    indent=4)\n",
        "\n",
        "  # process train\n",
        "  chanks_train = codecs.open(f'{constants.BASE_DATASET_PATH}/{subject}/X_train_chunks.json', 'r', encoding='utf-8').read()\n",
        "  chanks_train = json.loads(chanks_train)\n",
        "  chanks_train = np.array(chanks_train)\n",
        "\n",
        "  chanks_train_asr = apply_asr(chanks_train, constants.freq, M, T)\n",
        "  chanks_train_asr = chanks_train_asr.tolist()\n",
        "  json.dump(chanks_train_asr, codecs.open(f'{output_path_subject}/X_train_chunks.json', 'w', encoding='utf-8'),\n",
        "    separators=(',', ':'),\n",
        "    sort_keys=True,\n",
        "    indent=4)\n",
        "\n",
        "  json.dump(experiment_settings, codecs.open(f'{output_path_subject}/experiment_settings.json', 'w', encoding='utf-8'),\n",
        "    separators=(',', ':'),\n",
        "    sort_keys=True,\n",
        "    indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M95_F6QqHDvH",
        "outputId": "fe1a0c41-0453-4a9d-f1a8-071accac798c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sub-016\n",
            "[ASR] Determining channel-wise rejection thresholds\n",
            "[ASR] Calibrating...\n",
            "[ASR] Calibration done.\n",
            "[apply_asr]\n",
            "data_chanks_list_train shape =  (2996, 33, 100)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2996/2996 [00:53<00:00, 56.06it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[apply_asr]\n",
            "data_chanks_list_train shape =  (24175, 33, 100)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24175/24175 [06:56<00:00, 58.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sub-017\n",
            "[ASR] Determining channel-wise rejection thresholds\n",
            "[ASR] Calibrating...\n",
            "[ASR] Calibration done.\n",
            "[apply_asr]\n",
            "data_chanks_list_train shape =  (2996, 33, 100)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2996/2996 [00:53<00:00, 56.52it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[apply_asr]\n",
            "data_chanks_list_train shape =  (16436, 33, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16436/16436 [04:34<00:00, 59.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dmLslanPHDxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dG5nEm_OMrSI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}