{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7WFBF3IaFjN"
      },
      "source": [
        "# SLF"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acknowledgment\n",
        "This project includes code adapted from [Surface-Laplacian](https://github.com/alberto-ara/Surface-Laplacian/tree/master),\n",
        "created by Alberto Ara and licensed under the MIT License."
      ],
      "metadata": {
        "id": "x_BkVY_7nH39"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48Addw44_ll8",
        "outputId": "cfa5a60f-1201-4d87-aff7-4281d8b3c82c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM2Lr6HxDaA8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import codecs, json\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import time\n",
        "from scipy import special\n",
        "import math\n",
        "\n",
        "import sys\n",
        "sys.path.append('drive/MyDrive/BmiResearch')\n",
        "\n",
        "from constants import constants\n",
        "from utils.debugger import logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8dWPuabDAb1"
      },
      "outputs": [],
      "source": [
        "output_path = f'{constants.PREPROCESSED_DATASET_PATH}/SLF'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7-se8zorkO_"
      },
      "outputs": [],
      "source": [
        "def surface_laplacian(epochs, m=4, leg_order=50, smoothing=1e-5,):\n",
        "    # Part of this code is adapted from [alberto-ara/Surface-Laplacian] (https://github.com/alberto-ara/Surface-Laplacian/tree/master)\n",
        "    # Copyright (c) 2017 Alberto Ara\n",
        "    # Licensed under the MIT License (https://github.com/alberto-ara/Surface-Laplacian/blob/master/LICENSE)\n",
        "\n",
        "    montage = {'F5': np.array([-63.058,  54.038,  18.126]), 'F3': np.array([-48.2  ,  57.551,  39.87 ]),\n",
        "               'Fz': np.array([-0.   , 60.738, 59.463]), 'F4': np.array([48.143, 57.584, 39.892]),\n",
        "               'F6': np.array([63.045, 54.026, 18.208]), 'FC3': np.array([-59.275,  30.955,  52.471]),\n",
        "               'FC1': np.array([-32.351,  32.436,  71.598]), 'FC2': np.array([32.351, 32.436, 71.598]),\n",
        "               'FC4': np.array([59.275, 30.955, 52.471]), 'C5': np.array([-8.0832e+01,  4.9495e-15,  2.6292e+01]),\n",
        "               'C3': np.array([-6.3171e+01,  3.8681e-15,  5.6872e+01]), 'C1': np.array([-3.4537e+01,  2.1148e-15,  7.7667e+01]),\n",
        "               'Cz': np.array([-0.0000e+00,  5.2047e-15,  8.5000e+01]), 'C2': np.array([3.4609e+01, 2.1192e-15, 7.7635e+01]),\n",
        "               'C4': np.array([6.3167e+01, 3.8679e-15, 5.6876e+01]), 'C6': np.array([8.0832e+01, 4.9495e-15, 2.6292e+01]),\n",
        "               'CP5': np.array([-76.247, -28.763,  24.167]), 'CP3': np.array([-59.275, -30.955,  52.471]),\n",
        "               'CP1': np.array([-32.351, -32.436,  71.598]), 'CPz': np.array([ 4.0325e-15, -3.2928e+01,  7.8363e+01]),\n",
        "               'CP2': np.array([ 32.351, -32.436,  71.598]), 'CP4': np.array([ 59.275, -30.955,  52.471]),\n",
        "               'CP6': np.array([ 76.247, -28.763,  24.167]), 'P5': np.array([-63.058, -54.038,  18.126]),\n",
        "               'P3': np.array([-48.2  , -57.551,  39.87 ]), 'Pz': np.array([ 7.4383e-15, -6.0738e+01,  5.9463e+01]),\n",
        "               'P4': np.array([ 48.143, -57.584,  39.892]), 'P6': np.array([ 63.045, -54.026,  18.208]),\n",
        "               'PO3': np.array([-31.483, -76.153,  20.847]), 'PO4': np.array([ 31.483, -76.153,  20.847]),\n",
        "               'O1': np.array([-26.133 , -80.784 ,  -4.0011]), 'Oz': np.array([ 1.0407e-14, -8.4981e+01, -1.7860e+00]),\n",
        "               'O2': np.array([ 26.133 , -80.784 ,  -4.0011])}\n",
        "\n",
        "\n",
        "    # get electrodes positions\n",
        "    locs = np.array(list(montage.values()))\n",
        "\n",
        "    x = locs[:, 0]\n",
        "    y = locs[:, 1]\n",
        "    z = locs[:, 2]\n",
        "\n",
        "    # arrange data\n",
        "    #     print(epochs.shape)\n",
        "    data = epochs.T  # np.rollaxis(epochs, 0, 3)\n",
        "    orig_data_size = np.squeeze(data.shape)\n",
        "\n",
        "    numelectrodes = len(x)\n",
        "\n",
        "    # normalize cartesian coordenates to sphere unit\n",
        "    def cart2sph(x, y, z):\n",
        "        hxy = np.hypot(x, y)\n",
        "        r = np.hypot(hxy, z)\n",
        "        el = np.arctan2(z, hxy)\n",
        "        az = np.arctan2(y, x)\n",
        "        return az, el, r\n",
        "\n",
        "    junk1, junk2, spherical_radii = cart2sph(x, y, z)\n",
        "    maxrad = np.max(spherical_radii)\n",
        "    x = x / maxrad\n",
        "    y = y / maxrad\n",
        "    z = z / maxrad\n",
        "\n",
        "    # compute cousine distance between all pairs of electrodes\n",
        "    cosdist = np.zeros((numelectrodes, numelectrodes))\n",
        "    for i in range(numelectrodes):\n",
        "        for j in range(i + 1, numelectrodes):\n",
        "            cosdist[i, j] = 1 - (((x[i] - x[j]) ** 2 + (y[i] - y[j]) ** 2 + (z[i] - z[j]) ** 2) / 2)\n",
        "\n",
        "    cosdist = cosdist + cosdist.T + np.identity(numelectrodes)\n",
        "\n",
        "    # get legendre polynomials\n",
        "    legpoly = np.zeros((leg_order, numelectrodes, numelectrodes))\n",
        "    for ni in range(leg_order):\n",
        "        for i in range(numelectrodes):\n",
        "            for j in range(i + 1, numelectrodes):\n",
        "                # temp = special.lpn(8,cosdist[0,1])[0][8]\n",
        "                legpoly[ni, i, j] = special.lpn(ni + 1, cosdist[i, j])[0][ni + 1]\n",
        "\n",
        "    legpoly = legpoly + np.transpose(legpoly, (0, 2, 1))\n",
        "\n",
        "    for i in range(leg_order):\n",
        "        legpoly[i, :, :] = legpoly[i, :, :] + np.identity(numelectrodes)\n",
        "\n",
        "    # compute G and H matrixes\n",
        "    twoN1 = np.multiply(2, range(1, leg_order + 1)) + 1\n",
        "    gdenom = np.power(np.multiply(range(1, leg_order + 1), range(2, leg_order + 2)), m, dtype=float)\n",
        "    hdenom = np.power(np.multiply(range(1, leg_order + 1), range(2, leg_order + 2)), m - 1, dtype=float)\n",
        "\n",
        "    G = np.zeros((numelectrodes, numelectrodes))\n",
        "    H = np.zeros((numelectrodes, numelectrodes))\n",
        "\n",
        "    for i in range(numelectrodes):\n",
        "        for j in range(i, numelectrodes):\n",
        "\n",
        "            g = 0\n",
        "            h = 0\n",
        "\n",
        "            for ni in range(leg_order):\n",
        "                g = g + (twoN1[ni] * legpoly[ni, i, j]) / gdenom[ni]\n",
        "                h = h - (twoN1[ni] * legpoly[ni, i, j]) / hdenom[ni]\n",
        "\n",
        "            G[i, j] = g / (4 * math.pi)\n",
        "            H[i, j] = -h / (4 * math.pi)\n",
        "\n",
        "    G = G + G.T\n",
        "    H = H + H.T\n",
        "\n",
        "    G = G - np.identity(numelectrodes) * G[1, 1] / 2\n",
        "    H = H - np.identity(numelectrodes) * H[1, 1] / 2\n",
        "\n",
        "    if np.any(orig_data_size == 1):\n",
        "        data = data[:]\n",
        "    else:\n",
        "        data = np.reshape(data, (orig_data_size[0], np.prod(orig_data_size[1:3])))\n",
        "\n",
        "    # compute C matrix\n",
        "    Gs = G + np.identity(numelectrodes) * smoothing\n",
        "    GsinvS = np.sum(np.linalg.inv(Gs), 0)\n",
        "    dataGs = np.dot(data.T, np.linalg.inv(Gs))\n",
        "    C = dataGs - np.dot(np.atleast_2d(np.sum(dataGs, 1) / np.sum(GsinvS)).T, np.atleast_2d(GsinvS))\n",
        "    surf_lap = np.reshape(np.transpose(np.dot(C, np.transpose(H))), orig_data_size)\n",
        "    return surf_lap.T  # np.rollaxis(surf_lap, 2, 0)\n",
        "\n",
        "\n",
        "def apply_slf(data_chanks_list_train):\n",
        "    print('[apply_slf]')\n",
        "\n",
        "    final_train_set = []\n",
        "\n",
        "    for chank_df in tqdm(data_chanks_list_train):\n",
        "        sl_data = surface_laplacian(epochs=chank_df.T)\n",
        "        # scaled_data = standard_scaling(sl_data)\n",
        "        final_train_set.append(sl_data.T)\n",
        "    return np.array(final_train_set)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HE_4eVnWF8PQ",
        "outputId": "6ac05c86-5a55-4b25-8ab9-4cb0d894e228"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drive/MyDrive/BmiResearch/data/datasets/preprocessed/a_walk_in_the_park/SLF'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJwCaVf_F8Sm",
        "outputId": "d1cff60a-d7f3-4a33-ed55-f5c84f5710f1"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sub-017\n",
            "[apply_slf]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2996/2996 [15:02<00:00,  3.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[apply_slf]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16436/16436 [1:21:20<00:00,  3.37it/s]\n"
          ]
        }
      ],
      "source": [
        "for subject in sorted(os.listdir(constants.BASE_DATASET_PATH)):\n",
        "  print(subject)\n",
        "\n",
        "  experiment_settings = dict()\n",
        "\n",
        "  experiment_settings['general_params'] = {'low_filter':constants.low_filter,\n",
        "                                          'high_filter':constants.high_filter,\n",
        "                                          'frequency':constants.freq,\n",
        "                                          'minutes_for_test':constants.minutes_for_test,\n",
        "                                          'window_size':constants.window_size,\n",
        "                                          'overlap':constants.overlap,\n",
        "                                          'EEG_CHANNELS':constants.EEG_CHANNELS}\n",
        "  experiment_settings['signal_processing'] = 'SLF'\n",
        "  experiment_settings['DateTime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "  experiment_settings['BASE_DATASET_PATH'] = constants.BASE_DATASET_PATH\n",
        "  experiment_settings['OUTPUT_PATH'] = output_path\n",
        "\n",
        "  output_path_subject = (f'{output_path}/{subject}')\n",
        "  os.makedirs(output_path_subject)\n",
        "\n",
        "  experiment_settings[subject] = dict()\n",
        "\n",
        "  # Fit SLF\n",
        "  fit_df = codecs.open(f'{constants.BASE_DATASET_PATH}/{subject}/X_fit.json', 'r', encoding='utf-8').read()\n",
        "  fit_df = json.loads(fit_df)\n",
        "  fit_df = np.array(fit_df)\n",
        "  fit_df_slf = surface_laplacian(epochs=fit_df, m=4, leg_order=50, smoothing=1e-5)\n",
        "\n",
        "  fit_df_slf = fit_df_slf.tolist()\n",
        "  json.dump(fit_df_slf, codecs.open(f'{output_path_subject}/X_fit.json', 'w', encoding='utf-8'),\n",
        "    separators=(',', ':'),\n",
        "    sort_keys=True,\n",
        "    indent=4)\n",
        "\n",
        "  # process test\n",
        "  chanks_test = codecs.open(f'{constants.BASE_DATASET_PATH}/{subject}/X_test_chunks.json', 'r', encoding='utf-8').read()\n",
        "  chanks_test = json.loads(chanks_test)\n",
        "  chanks_test = np.array(chanks_test)\n",
        "\n",
        "  starttime = time.perf_counter()\n",
        "  chanks_test_slf = apply_slf(chanks_test)\n",
        "  slf_proc_end = time.perf_counter() - starttime\n",
        "  slf_proc_1ch_s = round(slf_proc_end / chanks_test.shape[0], 5)\n",
        "  experiment_settings[subject]['proc_1_test_ch_s'] = slf_proc_1ch_s\n",
        "  experiment_settings[subject]['proc_test_s'] = round(slf_proc_end, 5)\n",
        "  experiment_settings[subject]['len_test'] = chanks_test.shape[0]\n",
        "  experiment_settings[subject]['output_path_subject'] = output_path_subject\n",
        "\n",
        "  chanks_test_slf = chanks_test_slf.tolist()\n",
        "  json.dump(chanks_test_slf, codecs.open(f'{output_path_subject}/X_test_chunks.json', 'w', encoding='utf-8'),\n",
        "    separators=(',', ':'),\n",
        "    sort_keys=True,\n",
        "    indent=4)\n",
        "\n",
        "  # process train\n",
        "  chanks_train = codecs.open(f'{constants.BASE_DATASET_PATH}/{subject}/X_train_chunks.json', 'r', encoding='utf-8').read()\n",
        "  chanks_train = json.loads(chanks_train)\n",
        "  chanks_train = np.array(chanks_train)\n",
        "  chanks_train_slf = apply_slf(chanks_train)\n",
        "\n",
        "  chanks_train_slf = chanks_train_slf.tolist()\n",
        "  json.dump(chanks_train_slf, codecs.open(f'{output_path_subject}/X_train_chunks.json', 'w', encoding='utf-8'),\n",
        "    separators=(',', ':'),\n",
        "    sort_keys=True,\n",
        "    indent=4)\n",
        "\n",
        "  json.dump(experiment_settings, codecs.open(f'{output_path_subject}/experiment_settings.json', 'w', encoding='utf-8'),\n",
        "    separators=(',', ':'),\n",
        "    sort_keys=True,\n",
        "    indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EOgbatqttib",
        "outputId": "8cfeb216-e2b8-425d-d751-4f12194f966a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2996, 25, 100)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chanks_test = codecs.open(f'{constants.BASE_DATASET_PATH}/{subject}/X_test_chunks.json', 'r', encoding='utf-8').read()\n",
        "chanks_test = json.loads(chanks_test)\n",
        "chanks_test = np.array(chanks_test)\n",
        "chanks_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUdq7Trwc-YR",
        "outputId": "1adc58ef-170b-43cd-dbfb-198f84886d98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2996,)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test_chunks = codecs.open(file_path, 'r', encoding='utf-8').read()\n",
        "y_test_chunks = json.loads(y_test_chunks)\n",
        "y_test_chunks = np.array(y_test_chunks)\n",
        "y_test_chunks.shape"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}